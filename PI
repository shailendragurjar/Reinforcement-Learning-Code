#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Tue Aug 29 21:32:19 2017

@author: shailendragurjar
"""
import numpy as np

states = 44
actions = 2
gamma = 0.99
batch_size = 11
batch_num = states/batch_size
    

np.random.seed(22)
T = np.reshape([np.random.sample() for i in range(states*actions*states)], [states, actions, states]) 
R = np.reshape([np.random.uniform(-1,1,states*actions*states)],[states, actions, states])
T = T/np.expand_dims(np.sum(T, axis=2), axis=2)

# initialize policy and value arbitrarily
policy = [0 for s in range(states)]
old_pol = list(policy)
V = np.zeros(states)

# PI Howard
print "Initial policy", policy
# print V
# print P
# print R


is_value_changed = True
iterations = 0
while is_value_changed:
    is_value_changed = False
    iterations += 1
    print "Iterations:", iterations

    # run value iteration for each state
    for s in range(states):
        V[s] = sum([T[s,policy[s],s1] * (R[s,policy[s],s1] + gamma*V[s1]) for s1 in range(states)])
        # print "Run for state", s

    for s in range(states):
        q_best = V[s]
        # print "State", s, "q_best", q_best
        for a in range(actions):
            j=batch_num
            q_sa = sum([T[s, a, s1] * (R[s, a, s1] + gamma * V[s1]) for s1 in range(states)])
            if q_sa > q_best:
                print "State", s, ": q_sa", q_sa, "q_best", q_best
                while j :
                    print j
                    if (s in range(batch_size*j-batch_size,batch_size*j)):
                        policy[s] = a
                        break
               #     else:
               #         policy[s] = policy[s]
                    j = j-1
    print policy
    if (np.equal(old_pol,policy).all()):
        is_value_changed = False
    else:
        old_pol = list(policy)
        is_value_changed = True
        
    print "Policy now", policy
    print "V", V

print "Final policy"
print policy
print V

#x = np.random.randint(2, size=10)



